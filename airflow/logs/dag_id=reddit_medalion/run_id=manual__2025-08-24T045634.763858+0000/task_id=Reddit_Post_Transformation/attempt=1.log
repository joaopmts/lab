{"timestamp":"2025-08-24T04:56:35.356741","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-08-24T04:56:35.357202","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/reddit_dag_v3_medalion_spark.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-24T04:56:35.604952","level":"warning","event":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/connection.py:471: DeprecationWarning: Using Connection.get_connection_from_secrets from `airflow.models` is deprecated.Please use `from airflow.sdk import Connection` instead\n  warnings.warn(\n","logger":"py.warnings"}
{"timestamp":"2025-08-24T04:56:35.610409","level":"info","event":"Connection Retrieved 'spark_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-08-24T04:56:35.611317","level":"info","event":"Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.endpoint=http://minio:9000 --conf spark.hadoop.fs.s3a.access.key=eDFFCzvdNdoeLlJkZhXI --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --driver-class-path /opt/airflow/conf/jars/hadoop-aws-3.3.4.jar,/opt/airflow/conf/jars/aws-java-sdk-bundle-1.12.262.jar --jars /opt/airflow/conf/jars/hadoop-aws-3.3.4.jar,/opt/airflow/conf/jars/aws-java-sdk-bundle-1.12.262.jar --name reddit_transformation --verbose --deploy-mode client /opt/airflow/dags/scripts/spark/reddit_transformation_user.py --src hdfs://namenode:8020/teste/reddit --to hdfs://namenode:8020/teste/reddit/output","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.392216","level":"info","event":"Using properties file: null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.464853","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.464965","level":"info","event":"master                  spark://spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465000","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465027","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465053","level":"info","event":"executorMemory          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465074","level":"info","event":"executorCores           null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465095","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465116","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465136","level":"info","event":"driverMemory            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465156","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465177","level":"info","event":"driverExtraClassPath    /opt/airflow/conf/jars/hadoop-aws-3.3.4.jar,/opt/airflow/conf/jars/aws-java-sdk-bundle-1.12.262.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465197","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465216","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465235","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465254","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465272","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465290","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465310","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465330","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465349","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465369","level":"info","event":"primaryResource         file:/opt/airflow/dags/scripts/spark/reddit_transformation_user.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465390","level":"info","event":"name                    reddit_transformation","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465412","level":"info","event":"childArgs               [--src hdfs://namenode:8020/teste/reddit --to hdfs://namenode:8020/teste/reddit/output]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465436","level":"info","event":"jars                    file:/opt/airflow/conf/jars/hadoop-aws-3.3.4.jar,file:/opt/airflow/conf/jars/aws-java-sdk-bundle-1.12.262.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465458","level":"info","event":"packages                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465478","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465497","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465517","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465540","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465564","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465586","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465605","level":"info","event":"(spark.driver.extraClassPath,/opt/airflow/conf/jars/hadoop-aws-3.3.4.jar,/opt/airflow/conf/jars/aws-java-sdk-bundle-1.12.262.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465624","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465648","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465668","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://minio:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465688","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465707","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465726","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465745","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.465766","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.656734","level":"info","event":"25/08/24 04:56:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.762617","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.762733","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.762804","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.762838","level":"info","event":"file:/opt/airflow/dags/scripts/spark/reddit_transformation_user.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.762865","level":"info","event":"null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.762890","level":"info","event":"--src","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.762912","level":"info","event":"hdfs://namenode:8020/teste/reddit","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.762933","level":"info","event":"--to","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.762955","level":"info","event":"hdfs://namenode:8020/teste/reddit/output","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.764652","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.764717","level":"info","event":"(spark.app.name,reddit_transformation)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.764748","level":"info","event":"(spark.app.submitTime,1756011396748)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.764773","level":"info","event":"(spark.driver.extraClassPath,/opt/airflow/conf/jars/hadoop-aws-3.3.4.jar,/opt/airflow/conf/jars/aws-java-sdk-bundle-1.12.262.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.764810","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.764833","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.764854","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://minio:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.764874","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.764894","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.764914","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.764934","level":"info","event":"(spark.jars,file:///opt/airflow/conf/jars/hadoop-aws-3.3.4.jar,file:///opt/airflow/conf/jars/aws-java-sdk-bundle-1.12.262.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.764955","level":"info","event":"(spark.master,spark://spark-master:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.764975","level":"info","event":"(spark.repl.local.jars,file:///opt/airflow/conf/jars/hadoop-aws-3.3.4.jar,file:///opt/airflow/conf/jars/aws-java-sdk-bundle-1.12.262.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.764996","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.765015","level":"info","event":"(spark.submit.pyFiles,)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.765040","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.765060","level":"info","event":"file:///opt/airflow/conf/jars/hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.765080","level":"info","event":"file:///opt/airflow/conf/jars/aws-java-sdk-bundle-1.12.262.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.765236","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:36.765296","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:37.685640","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:37.685752","level":"info","event":"File \"/opt/airflow/dags/scripts/spark/reddit_transformation_user.py\", line 4, in <module>","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:37.687463","level":"info","event":"from plugins.hook.spark_hook import sparkhook","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:37.687539","level":"info","event":"ModuleNotFoundError: No module named 'plugins'","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:37.722827","level":"info","event":"25/08/24 04:56:37 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:37.723661","level":"info","event":"25/08/24 04:56:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-7ce46741-9a22-4857-80a2-c7cb62fcb4b9","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-24T04:56:37.761526","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"Cannot execute: spark-submit --master spark://spark-master:7077 --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.endpoint=http://minio:9000 --conf spark.hadoop.fs.s3a.access.key=eDFFCzvdNdoeLlJkZhXI --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --driver-class-path /opt/airflow/conf/jars/hadoop-aws-3.3.4.jar,/opt/airflow/conf/jars/aws-java-sdk-bundle-1.12.262.jar --jars /opt/airflow/conf/jars/hadoop-aws-3.3.4.jar,/opt/airflow/conf/jars/aws-java-sdk-bundle-1.12.262.jar --name reddit_transformation --verbose --deploy-mode client /opt/airflow/dags/scripts/spark/reddit_transformation_user.py --src hdfs://namenode:8020/teste/reddit --to hdfs://namenode:8020/teste/reddit/output. Error code is: 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":890,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1177,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":397,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py","lineno":197,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py","lineno":566,"name":"submit"}],"is_group":false,"exceptions":[]}]}
