{"timestamp":"2025-08-24T10:46:10.659923","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-08-24T10:46:10.660354","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/reddit_bronze.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-24T10:46:11.136243","level":"warning","event":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/connection.py:471: DeprecationWarning: Using Connection.get_connection_from_secrets from `airflow.models` is deprecated.Please use `from airflow.sdk import Connection` instead\n  warnings.warn(\n","logger":"py.warnings"}
{"timestamp":"2025-08-24T10:46:11.147845","level":"info","event":"Connection Retrieved 'spark_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-08-24T10:46:12.117825Z","level":"error","event":"25/08/24 10:46:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"task"}
{"timestamp":"2025-08-24T10:46:12.230343Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"task"}
{"timestamp":"2025-08-24T10:46:12.230766Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"task"}
{"timestamp":"2025-08-24T10:46:14.216039Z","level":"error","event":"25/08/24 10:46:14 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties","chan":"stderr","logger":"task"}
{"timestamp":"2025-08-24T10:46:14.895162Z","level":"error","event":"25/08/24 10:46:14 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.","chan":"stderr","logger":"task"}
{"timestamp":"2025-08-24T10:46:30.425347Z","level":"error","event":"\r[Stage 0:>                                                          (0 + 0) / 2]\r25/08/24 10:46:30 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","chan":"stderr","logger":"task"}
{"timestamp":"2025-08-24T10:46:45.424706Z","level":"error","event":"25/08/24 10:46:45 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","chan":"stderr","logger":"task"}
{"timestamp":"2025-08-24T10:47:00.424843Z","level":"error","event":"25/08/24 10:47:00 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","chan":"stderr","logger":"task"}
{"timestamp":"2025-08-24T10:47:10.143227","level":"info","event":"Done. Returned value was: None","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator"}
{"timestamp":"2025-08-24T10:47:10.524828Z","level":"error","event":"\r[Stage 0:>                                                          (0 + 2) / 2]","chan":"stderr","logger":"task"}
